---
title: Introduction
description: Maxim AI is a cutting-edge Generative AI evaluation platform designed to bridge the gap between creating a compelling proof-of-concept (PoC) and then taking that to production ensuring quality and reliability. As engineers navigate the complexities of developing AI solutions, Maxim AI provides the necessary tools to give developers the ability to not only ship features faster but also with confidence. 
---

## Product overview

Maxim’s unified evaluation and observability framework streamlines the entire lifecycle of AI applications, right from experimentation to pre-release testing for quality and functionality, post-release monitoring, and data management. Maxim’s goal is to help development teams ship better-quality AI products, faster.

Maxim’s developer stacks empower teams to bring the best practices of traditional software development into their non-deterministic AI workflows. The five core pieces of our stack are:

## 1.  Experimentation: 
We have Playground++ built for AI teams’ prompt engineering needs that empower them to rapidly and systematically iterate in collaboration with their team. It enables developers to:
   
    1. Test, iterate, manage, and version prompts
    2. Deploy prompts with different deployment variables and experimentation strategies without any code changes enabling teams to seamlessly execute prompt A/B testing
    3. Run side-by-side bulk experiments on different permutations and combinations of prompts and models to identify the right prompt-model combination for your use case
    4. Simplify decision-making by comparing output quality, cost, and latency across different combinations of prompts, model, and model parameters
    
## 2. Datasets: 
Data management for teams that enables them to seamlessly curate datasets for their team’s evaluation and fine-tuning needs.
    1. Seamlessly import your datasets with a few clicks
    2. Continuously curate and evolve your datasets from sources like production data
    3. Enrich data using in-house or Maxim-managed data labeling and feedback
    4. you have the ability to create or import datasets with images, audio, or any other files thus empowering you to use and evaluate your multimodal AI Applications
## 3. Evaluator Store: 
Access to an evaluator store containing both general-purpose popular evaluators and domain-specific evaluators including both Maxim-created and 3rd party evaluators
    1. You get access to a variety of evaluators through the evaluator store that you can use off the shelf directly.
2. The platform also offers the flexibility to create your own evaluators suited to your specific application needs
3. You have the ability to customize the evaluators’ configurations to determine what pass/fail means for your application
4. The platform provides a unified framework for machine and human evaluations to come together to form a powerful quality report
## 4. Offline evaluations: 
Maxim provides a comprehensive toolkit for your pre release testing needs to enable you to quantitatively determine the quality of your application

    1. Measure the quality of your prompts or workflows quantitatively using the different categories of evaluators from the store such as AI, Programmatic, or Statistical evaluators
    2. Visualise evaluation runs on large test suites across multiple versions of prompts or application workflow 
    3. Integrate seamlessly with your existing CI/CD workflows
    4. Simplify human evaluation pipelines right from review request to collection and analysis of human feedback.

## 4. Observability:
Maxim Observability suite empowers developers to monitor real-time production logs and run them through periodic quality checks to ensure quality in production
1. Log and analyze production data using distributed tracing
2. Track and debug live issues and resolve them quickly
3. Measure in-production quality using automated evaluations
4. Improve quality and safety guarantees using real-time alerts

## Enterprise-First Design

Our product is designed with an enterprise-first approach at its core. From the ground up, we've crafted every aspect with the needs of large AI organisations in mind, including seamless in-VPC deployments, robust compliance measures, and enhanced collaboration features.


<Cards>
  <Card title="AI Evaluators" href="https://nextjs.org/docs" />
  <Card title="API-Based Evaluators" href="https://fumadocs.vercel.app" />
  
</Cards>

