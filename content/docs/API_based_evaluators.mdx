---
title: API-Based Evaluators
description: If you have developed your own fine-tuned models for tasks such as semantic similarity or consistency, you can integrate your evaluator endpoint into Maxim for evaluation via the API evaluator.
---
# Create an Demo API-based Sentiment Analysis Model
To demonstrate this feature, we have developed a demo model for sentiment analysis. 

The model assigns a score to a given text where a negative score indicates negative sentiment, a positive score indicates positive sentiment and a score of 0 indicates a balanced sentiment. For example:

- `"I hate you"` has a score of `-0.81`, indicating a negative sentiment.
- `"I am so happy to see this rainbow"` has a score of `0.51` , indicating a positive sentiment.

In the following steps, we will integrate this model into Maxim using the API evaluator.

```py title="model.py"
import nltk
from textblob import TextBlob

# TextBlob for sentiment analysis
def analyze_sentiment(text):
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity
    return polarity
  ```
In the above code, we use <a style={{color:"#FFA500"}} href="https://www.w3schools.com">`Textblob`</a> which is a library built on top of <a style={{color:"#FFA500"}} href="https://www.w3schools.com">`NLTK`</a> and Pattern and measures polarity as part of its sentiment analysis capabilities. Polarity indicates the sentiment expressed in a text, ranging from -**1** to  **1**, where:

- **1** represents a very negative sentiment,
- **0** represents a neutral sentiment,
- **1** represents a very positive sentiment.

<a style={{color:"#FFA500"}} href="https://www.w3schools.com">`Textblob`</a>  analyzes the text by breaking it down into individual words and phrases, then evaluates the sentiment based on a predefined `lexicon` where words are scored for their positive or negative sentiment. The overall `polarity` score is the average of the individual scores of words and phrases in the text.

```py title="flask.py"
from flask import Flask
from flask import request
app = Flask(__name__)

@app.route('/model',methods=['POST'])
def sentiment():
    body = request.get_json()
    print(body)
    output = analyze_sentiment(body['query'])
    response = {'response':output}
    return response
    

# main driver function
if __name__ == '__main__':
  app.run(port=8000)

 ```
We then created a <a style={{color:"#FFA500"}} href="https://www.w3schools.com">`Flask`</a> app and exposed it to the public via an API using <a style={{color:"#FFA500"}} href="https://www.w3schools.com">`Ngrok`</a>  . This can now be utilized on the Maxim platform for evaluation through the API evaluator. 

# Bring your API-based Evaluator to Maxim
<img src="./API_based_eval/img1.png" alt="chameleon" />

To create an API-based evaluator you will have to follow these steps :
<Steps>
<Step>
  ***Select "Evaluators" from the left panel.***
</Step>
 
<Step>
  ***Click on the "+" icon.***
</Step>
<Step>
***Choose "API-based".***
</Step>
<Step>
 ***A UI will open where you can enter your API endpoint.***
</Step>
</Steps>
<img src="./API_based_eval/img2.png" alt="chameleon" />
Then you will need to:
<Steps>
<Step>
 ***Enter the API endpoint as done in the workflow.***
</Step>
 
<Step>
 ***In the Body, map the query to the output of your application.***
</Step>
<Step>
***Map the score to the endpoint output.***
</Step>
<Step>
 ***Optionally, map the reasoning.***
</Step>
<Step>
***Select the pass criteria for each query and for every run.***
</Step>
<Step>
***Finally, save the evaluator to use it in the workflow.***
</Step>
</Steps>
<img src="./API_based_eval/img3.png" alt="chameleon" />
As you can see in the report, when each output is sent to the API evaluator, it returns a `polarity score`. A score greater than **0** indicates `positive sentiment`, while a score less than **0** indicates `negative sentiment`.

<Cards>
  <Card title="AI Evaluators" href="https://nextjs.org/docs" />
  <Card title="Machine Evaluators" href="https://fumadocs.vercel.app" />
  
</Cards>

